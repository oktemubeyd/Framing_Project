{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Necessary Libraries"
      ],
      "metadata": {
        "id": "GB9mS0Cki2_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZVsMiLTocR2l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import re\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Data"
      ],
      "metadata": {
        "id": "y1yAUeoki9Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"FinalUsedAnnotations.xlsx\")[['Body', 'Economic_Relationship']]"
      ],
      "metadata": {
        "id": "UI85nXKOcZpN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6SQfviFrcaZW",
        "outputId": "339a1600-fb35-43f0-8ba5-3a9f2d7c9b51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Body  Economic_Relationship\n",
              "0    \\n                Sosyal medya platformu TikTo...                      0\n",
              "1    \\n                Çin Dışişleri Bakanlığından ...                      1\n",
              "2    \\n                Çin Dışişleri Bakanlığı'nın ...                      0\n",
              "3    \\n                    Otomotiv sektöründeki fu...                      0\n",
              "4    \\n                Çin Merkez Bankasının (PBoC)...                      0\n",
              "..                                                 ...                    ...\n",
              "603  'Çelikte Çin'in geri kalacağı pazarlardaki tal...                      1\n",
              "604  Aksa Jeneratör ile Mitsubishi ortak şirket kur...                      1\n",
              "605  VakıfBank’a Çin’den 140 milyon dolar kaynakVak...                      1\n",
              "606  Bursa’da bisiklet coşkusu başladı‘Bursa’da Bis...                      0\n",
              "607  TEİ, ortaklık anlaşması yenilendiMilli Savunma...                      0\n",
              "\n",
              "[608 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a56d4207-2a38-454d-aa48-2920b69b799e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Economic_Relationship</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n                Sosyal medya platformu TikTo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n                Çin Dışişleri Bakanlığından ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n                Çin Dışişleri Bakanlığı'nın ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n                    Otomotiv sektöründeki fu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n                Çin Merkez Bankasının (PBoC)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>'Çelikte Çin'in geri kalacağı pazarlardaki tal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>Aksa Jeneratör ile Mitsubishi ortak şirket kur...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>605</th>\n",
              "      <td>VakıfBank’a Çin’den 140 milyon dolar kaynakVak...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>Bursa’da bisiklet coşkusu başladı‘Bursa’da Bis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>TEİ, ortaklık anlaşması yenilendiMilli Savunma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>608 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a56d4207-2a38-454d-aa48-2920b69b799e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a56d4207-2a38-454d-aa48-2920b69b799e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a56d4207-2a38-454d-aa48-2920b69b799e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c5d758ee-9427-45f3-8de9-f6b7a98bdf6e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5d758ee-9427-45f3-8de9-f6b7a98bdf6e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c5d758ee-9427-45f3-8de9-f6b7a98bdf6e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4bbed1e2-8355-4e4a-833d-818164cd5feb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4bbed1e2-8355-4e4a-833d-818164cd5feb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 608,\n  \"fields\": [\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 608,\n        \"samples\": [\n          \"\\n                _x000D_\\n\\u00c7in D\\u0131\\u015fi\\u015fleri Bakanl\\u0131\\u011f\\u0131, Irak\\u2019\\u0131n toprak b\\u00fct\\u00fcnl\\u00fc\\u011f\\u00fc, ulusal istikrar\\u0131 ve birli\\u011fini korumak i\\u00e7in g\\u00f6sterdi\\u011fi \\u00e7abalar\\u0131 desteklediklerini a\\u00e7\\u0131klad\\u0131._x000D_\\nBakanl\\u0131k S\\u00f6zc\\u00fcs\\u00fc Lu Kang, Pekin\\u2019de d\\u00fczenledi\\u011fi ola\\u011fan bas\\u0131n toplant\\u0131s\\u0131nda, Irak ordusunun Kerk\\u00fck\\u2019e girmesiyle ilgili olarak \\u201cPrensip olarak, Irak h\\u00fck\\u00fcmetinin toprak b\\u00fct\\u00fcnl\\u00fc\\u011f\\u00fcn\\u00fc, ulusal istikrar\\u0131n\\u0131, birli\\u011fini korumak i\\u00e7in verdi\\u011fi \\u00e7abalar\\u0131 destekliyoruz.\\u201d ifadelerini kulland\\u0131._x000D_\\nLu, ilgili taraflar\\u0131n da Irak\\u2019\\u0131n bar\\u0131\\u015f, istikrar ve toprak b\\u00fct\\u00fcnl\\u00fc\\u011f\\u00fcn\\u00fc desteklemesini umdu\\u011funu s\\u00f6yledi.\\n            \",\n          \"\\n                ABD ve \\u00c7in, sorunlu ili\\u015fkilerini \\u00e7\\u00f6zmeye \\u00e7al\\u0131\\u015f\\u0131rken; Beyaz Saray, ABD Ba\\u015fkan\\u0131 Joe Biden ile \\u00c7in Devlet Ba\\u015fkan\\u0131 Xi Jinping aras\\u0131nda gelecek ay San Francisco'da y\\u00fcz y\\u00fcze bir g\\u00f6r\\u00fc\\u015fme yap\\u0131lmas\\u0131n\\u0131 planl\\u0131yor._x000D_\\nWashington Post'ta yer alan haber \\u00fcst d\\u00fczeydeki ABD'li yetkililere dayand\\u0131r\\u0131ld\\u0131._x000D_\\nD\\u00fcnyan\\u0131n en b\\u00fcy\\u00fck iki ekonomisi aras\\u0131ndaki ili\\u015fkiler son y\\u0131llarda Tayvan, koronavir\\u00fcs salg\\u0131n\\u0131, casusluk iddialar\\u0131, insan haklar\\u0131 sorunlar\\u0131 ve g\\u00fcmr\\u00fck vergileri gibi bir\\u00e7ok sorun nedeniyle gerilmi\\u015fti._x000D_\\nABD'li yetkililerden biri, g\\u00f6r\\u00fc\\u015fme olas\\u0131l\\u0131\\u011f\\u0131n\\u0131n \\\"son derece y\\u00fcksek\\\" oldu\\u011funu belirtti ve \\\"(planlama) s\\u00fcrecine ba\\u015fl\\u0131yoruz\\\" dedi.\\n            \",\n          \"\\n                Uluslararas\\u0131 kredi derecelendirme kurulu\\u015fu S&P, \\u00c7in ve Hong Kong'un kredi notlar\\u0131n\\u0131n g\\u00f6r\\u00fcn\\u00fcmlerini 'dura\\u011fan'dan 'negatif'e indirdi. \\u00c7in'in kredi notlar\\u0131n\\u0131 AA-/A-1+ olarak teyit eden S&P, Hong Kong'un notunu da AAA olarak tekrarlad\\u0131.\\u00a0S&P, \\u00c7in'in kredi notu g\\u00f6r\\u00fcn\\u00fcm\\u00fcn\\u00fc a\\u015fa\\u011f\\u0131 y\\u00f6nl\\u00fc revize edilmesinin, \\u00c7in h\\u00fck\\u00fcmetinin kredibilitesi i\\u00e7in ekonomik ve finansal risklerin yava\\u015f yava\\u015f artaca\\u011f\\u0131 beklentisini yans\\u0131tt\\u0131\\u011f\\u0131n\\u0131 bildirdi. Bununla birlikte \\u00c7in h\\u00fck\\u00fcmetinin ve \\u015firketlerin kald\\u0131ra\\u00e7 oranlar\\u0131n\\u0131n k\\u00f6t\\u00fcle\\u015fmelerinin muhtemel oldu\\u011funu ifade eden S&P, yat\\u0131r\\u0131m oran\\u0131n\\u0131n da GSYH'n\\u0131n y\\u00fczde 30-35'i gibi s\\u00fcrd\\u00fcr\\u00fclebilir seviyelerde olaca\\u011f\\u0131na inand\\u0131klar\\u0131n\\u0131 vurgulad\\u0131. \\u00a0S&P, \\u00c7in'in kredi notunun ise \\u00c7in h\\u00fck\\u00fcmetinin Mart ay\\u0131ndaki Ulusal Halk Kongresi'nde onaylanan reform ajandas\\u0131n\\u0131n ray\\u0131nda oldu\\u011fu g\\u00f6r\\u00fc\\u015f\\u00fcn\\u00fc, \\u00dclke'nin b\\u00fcy\\u00fcme g\\u00f6r\\u00fcn\\u00fcm\\u00fc ve g\\u00fc\\u00e7l\\u00fc d\\u0131\\u015f pozisyonunu yans\\u0131tt\\u0131\\u011f\\u0131n\\u0131 belirtirken, yuan\\u0131n uluslararas\\u0131 kullan\\u0131m\\u0131 art\\u0131k\\u00e7a \\u00c7in'in d\\u0131\\u015f pozisyonunun daha da g\\u00fc\\u00e7lenece\\u011fini de ifade etti.S&P, Hong Kong'un g\\u00f6r\\u00fcn\\u00fcm\\u00fcn\\u00fcn 'negatif'e revize edilmesine neden olarak ise \\u00c7in'in g\\u00f6r\\u00fcn\\u00fcm\\u00fcn\\u00fcn d\\u00fc\\u015f\\u00fcr\\u00fclmesini i\\u015faret etti. S&P, \\u00c7in ile Kong Kong aras\\u0131nda y\\u00fcksek derecede finansal ve ekonomik ba\\u011flant\\u0131 oldu\\u011funu savunurken, Hong Kong'un kredi notunun daha y\\u00fcksek olmas\\u0131na neden olarak ise Hong Kong'un kurumlar\\u0131n\\u0131n ve politikamar\\u0131n\\u0131n a\\u00e7\\u0131k ve serbest ekonomiyi desteklemesini g\\u00f6sterdi.\\n            \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Economic_Relationship\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Body'] = df['Body'].replace([None, ''], pd.NA)\n",
        "df = df.dropna()\n",
        "\n",
        "df['Economic_Relationship'] = df['Economic_Relationship'].replace([None, ''], pd.NA)\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "eQwS2GaIcbyi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Economic_Relationship').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "iMufCBEqcea8",
        "outputId": "2bd43678-d268-409e-f662-16fa7dbb5bc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Body\n",
              "Economic_Relationship      \n",
              "0                       404\n",
              "1                       204"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fc5f61c-8bb9-4650-ae1b-1661b17747c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Economic_Relationship</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc5f61c-8bb9-4650-ae1b-1661b17747c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fc5f61c-8bb9-4650-ae1b-1661b17747c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fc5f61c-8bb9-4650-ae1b-1661b17747c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c99ce998-d655-4bc4-ac23-b5f39952e618\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c99ce998-d655-4bc4-ac23-b5f39952e618')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c99ce998-d655-4bc4-ac23-b5f39952e618 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Economic_Relationship\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 141,\n        \"min\": 204,\n        \"max\": 404,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          204,\n          404\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and labels\n",
        "texts = df['Body'].tolist()\n",
        "labels = df['Economic_Relationship'].tolist()"
      ],
      "metadata": {
        "id": "gkkckLR_cf8F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Model"
      ],
      "metadata": {
        "id": "ZX1gseeXjD2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-cased')\n",
        "\n",
        "class NewspaperDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdGSomf9cjKG",
        "outputId": "f6adc3f1-b577-46b4-dca6-a9eeb5088b16"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training and evaluation functions\n",
        "def train_epoch(model, data_loader, optimizer, device, n_examples):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d['input_ids'].to(device)\n",
        "        attention_mask = d['attention_mask'].to(device)\n",
        "        labels = d['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.logits, dim=1)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, sum(losses) / n_examples\n",
        "\n",
        "def eval_model(model, data_loader, device, n_examples):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d['input_ids'].to(device)\n",
        "            attention_mask = d['attention_mask'].to(device)\n",
        "            labels = d['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            all_predictions.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = correct_predictions.double() / n_examples\n",
        "    avg_loss = sum(losses) / n_examples\n",
        "    class_report = classification_report(all_labels, all_predictions, output_dict=True)\n",
        "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # ✅ Now returns five values including predictions\n",
        "    return accuracy, avg_loss, class_report, conf_matrix, all_predictions"
      ],
      "metadata": {
        "id": "gzMXKq2mclXw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Data split\n",
        "train_idx, val_idx = train_test_split(\n",
        "    list(range(len(texts))), test_size=0.3, stratify=labels, random_state=2\n",
        ")\n",
        "train_texts = [texts[i] for i in train_idx]\n",
        "val_texts = [texts[i] for i in val_idx]\n",
        "train_labels = [labels[i] for i in train_idx]\n",
        "val_labels = [labels[i] for i in val_idx]\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "def objective(trial):\n",
        "    # Sample hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 5e-5, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    num_epochs = trial.suggest_int(\"num_epochs\", 3, 6)\n",
        "    seed = trial.suggest_int(\"seed\", 1, 10000)\n",
        "\n",
        "    # Set all seeds\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "    # Prepare data\n",
        "    train_dataset = NewspaperDataset(train_texts, train_labels, tokenizer)\n",
        "    val_dataset = NewspaperDataset(val_texts, val_labels, tokenizer)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        'dbmdz/bert-base-turkish-128k-cased', num_labels=2\n",
        "    ).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(num_epochs):\n",
        "        train_epoch(model, train_loader, optimizer, device, len(train_dataset))\n",
        "\n",
        "    # Evaluate\n",
        "    _, _, _, _, val_preds = eval_model(model, val_loader, device, len(val_dataset))\n",
        "    val_true = [val_labels[i] for i in range(len(val_preds))]\n",
        "\n",
        "    # Per-class precision, recall, f1\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(val_true, val_preds, average=None, labels=[0,1])\n",
        "    f1_macro = f1.mean()\n",
        "    f2_class_1 = (5 * precision[1] * recall[1]) / (4 * precision[1] + recall[1] + 1e-10)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf = confusion_matrix(val_true, val_preds, labels=[0, 1])\n",
        "    tn, fp, fn, tp = conf.ravel()\n",
        "\n",
        "    # Optional: log metrics as trial attributes (can be accessed later)\n",
        "    trial.set_user_attr(\"precision_0\", precision[0])\n",
        "    trial.set_user_attr(\"recall_0\", recall[0])\n",
        "    trial.set_user_attr(\"precision_1\", precision[1])\n",
        "    trial.set_user_attr(\"recall_1\", recall[1])\n",
        "    trial.set_user_attr(\"f1_macro\", f1_macro)\n",
        "    trial.set_user_attr(\"f2_class_1\", f2_class_1)\n",
        "    trial.set_user_attr(\"conf_matrix\", conf.tolist())  # so it's serializable\n",
        "    trial.set_user_attr(\"seed\", seed)\n",
        "\n",
        "    return f1_macro, f2_class_1  # still optimizing these\n",
        "\n",
        "\n",
        "\n",
        "# Multi-objective study\n",
        "study = optuna.create_study(directions=[\"maximize\", \"maximize\"])\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Show top trials\n",
        "print(\"\\n✅ Top Trials (F1-macro & F2-class1):\")\n",
        "for i, t in enumerate(study.best_trials):\n",
        "    print(f\"\\nTrial {i}\")\n",
        "    print(f\"F1-macro: {t.values[0]:.4f}, F2 (class 1): {t.values[1]:.4f}\")\n",
        "    print(f\"Precision (0): {t.user_attrs['precision_0']:.4f}, Recall (0): {t.user_attrs['recall_0']:.4f}\")\n",
        "    print(f\"Precision (1): {t.user_attrs['precision_1']:.4f}, Recall (1): {t.user_attrs['recall_1']:.4f}\")\n",
        "    print(f\"Seed: {t.user_attrs['seed']}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(np.array(t.user_attrs[\"conf_matrix\"]))\n",
        "\n",
        "# Optionally pick the one with highest F1 or F2\n",
        "best_trial = max(study.best_trials, key=lambda t: t.values[0])  # or `t.values[1]` for F2\n",
        "best_params = best_trial.params\n",
        "print(\"\\n🎯 Using best trial based on F1:\")\n",
        "print(f\"  F1 = {best_trial.values[0]:.4f}, F2 = {best_trial.values[1]:.4f}\")\n",
        "print(f\"  Params = {best_params}\")\n",
        "\n",
        "# Final model training with best params\n",
        "final_model = BertForSequenceClassification.from_pretrained(\n",
        "    'dbmdz/bert-base-turkish-128k-cased', num_labels=2\n",
        ").to(device)\n",
        "final_optimizer = AdamW(final_model.parameters(), lr=best_params[\"lr\"])\n",
        "\n",
        "train_dataset = NewspaperDataset(train_texts, train_labels, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
        "\n",
        "for epoch in range(best_params[\"num_epochs\"]):\n",
        "    train_epoch(final_model, train_loader, final_optimizer, device, len(train_dataset))\n",
        "\n",
        "torch.save(final_model.state_dict(), 'bert_model_optimized_dual.pth')\n",
        "print(\"\\n✅ Final model saved as 'bert_model_optimized_dual.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOk8msQHhIZB",
        "outputId": "78fd749b-2281-425f-f75f-187716a293cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-15 23:06:37,424] A new study created in memory with name: no-name-89e80728-8737-4422-b8c8-fbe6576ca15d\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:07:16,355] Trial 0 finished with values: [0.9204055003512999, 0.8986928104373212] and parameters: {'lr': 2.1711698213328696e-05, 'batch_size': 8, 'num_epochs': 4, 'seed': 3677}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:07:43,392] Trial 1 finished with values: [0.9336803610845716, 0.9354838709467947] and parameters: {'lr': 1.612178288783659e-05, 'batch_size': 16, 'num_epochs': 3, 'seed': 3361}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:08:12,652] Trial 2 finished with values: [0.934157590030419, 0.9455128204915144] and parameters: {'lr': 1.1534595709481159e-05, 'batch_size': 8, 'num_epochs': 3, 'seed': 6960}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:08:48,211] Trial 3 finished with values: [0.9574771784232365, 0.9577922077716309] and parameters: {'lr': 2.526098960983148e-05, 'batch_size': 16, 'num_epochs': 4, 'seed': 1495}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:09:31,445] Trial 4 finished with values: [0.9512130098640362, 0.9446254071457363] and parameters: {'lr': 3.6171668927571175e-05, 'batch_size': 16, 'num_epochs': 5, 'seed': 4664}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:10:05,065] Trial 5 finished with values: [0.939484126984127, 0.938511326840078] and parameters: {'lr': 4.2028768658605676e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 82}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:10:38,620] Trial 6 finished with values: [0.9320964749536178, 0.904605263138093] and parameters: {'lr': 4.0992744682577596e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 6816}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:11:27,783] Trial 7 finished with values: [0.9331784232365146, 0.9253246753040986] and parameters: {'lr': 3.511720424411021e-05, 'batch_size': 32, 'num_epochs': 6, 'seed': 4161}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:12:01,354] Trial 8 finished with values: [0.9221862427632225, 0.9294871794658736] and parameters: {'lr': 1.2217382383807642e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 9794}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:12:36,466] Trial 9 finished with values: [0.9108331979860322, 0.9235668789592376] and parameters: {'lr': 1.820197447403856e-05, 'batch_size': 16, 'num_epochs': 4, 'seed': 5315}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:13:09,976] Trial 10 finished with values: [0.9385245901639344, 0.9180327868652459] and parameters: {'lr': 3.125790360049679e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 2216}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:13:39,266] Trial 11 finished with values: [0.9284224250325945, 0.9424920127580716] and parameters: {'lr': 2.1951122795288268e-05, 'batch_size': 8, 'num_epochs': 3, 'seed': 2794}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:14:12,821] Trial 12 finished with values: [0.9139344262295082, 0.8852459016193442] and parameters: {'lr': 1.1401214307530607e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 4738}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:14:59,799] Trial 13 finished with values: [0.9336803610845716, 0.9354838709467947] and parameters: {'lr': 1.3517187237969356e-05, 'batch_size': 8, 'num_epochs': 5, 'seed': 7949}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:15:26,778] Trial 14 finished with values: [0.9390162623300453, 0.9283387621945962] and parameters: {'lr': 2.9830499665842963e-05, 'batch_size': 16, 'num_epochs': 3, 'seed': 9086}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:15:56,036] Trial 15 finished with values: [0.9515873015873015, 0.9546925566135408] and parameters: {'lr': 2.0924939852584303e-05, 'batch_size': 8, 'num_epochs': 3, 'seed': 6523}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:16:31,141] Trial 16 finished with values: [0.9399290966386555, 0.9485530546412516] and parameters: {'lr': 2.427208067182555e-05, 'batch_size': 16, 'num_epochs': 4, 'seed': 3920}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:17:06,237] Trial 17 finished with values: [0.9448961156278229, 0.9313725489994126] and parameters: {'lr': 4.397682224064506e-05, 'batch_size': 16, 'num_epochs': 4, 'seed': 8531}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:17:40,175] Trial 18 finished with values: [0.9052059052059052, 0.9206349206130965] and parameters: {'lr': 1.5557087899773045e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 6069}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:18:27,229] Trial 19 finished with values: [0.9453278008298756, 0.9415584415378647] and parameters: {'lr': 4.693930431194643e-05, 'batch_size': 8, 'num_epochs': 5, 'seed': 4276}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:19:02,350] Trial 20 finished with values: [0.9320964749536178, 0.904605263138093] and parameters: {'lr': 3.994080637332713e-05, 'batch_size': 16, 'num_epochs': 4, 'seed': 1561}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:19:58,303] Trial 21 finished with values: [0.9279149159663865, 0.932475884223245] and parameters: {'lr': 2.8676113207542002e-05, 'batch_size': 8, 'num_epochs': 6, 'seed': 780}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:20:32,221] Trial 22 finished with values: [0.9273809523809524, 0.9223300970666154] and parameters: {'lr': 1.1978705363205164e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 3873}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:21:21,423] Trial 23 finished with values: [0.8782049250467467, 0.9161490683000366] and parameters: {'lr': 1.6035897948901475e-05, 'batch_size': 32, 'num_epochs': 6, 'seed': 2743}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:22:02,743] Trial 24 finished with values: [0.939484126984127, 0.938511326840078] and parameters: {'lr': 1.1862791958768732e-05, 'batch_size': 32, 'num_epochs': 5, 'seed': 9353}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:22:51,777] Trial 25 finished with values: [0.9448961156278229, 0.9313725489994126] and parameters: {'lr': 1.586093078634806e-05, 'batch_size': 32, 'num_epochs': 6, 'seed': 863}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:23:29,840] Trial 26 finished with values: [0.9512130098640362, 0.9446254071457363] and parameters: {'lr': 4.8429732565241304e-05, 'batch_size': 8, 'num_epochs': 4, 'seed': 7258}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:24:21,170] Trial 27 finished with values: [0.9574771784232365, 0.9577922077716309] and parameters: {'lr': 2.0508589008460296e-05, 'batch_size': 16, 'num_epochs': 6, 'seed': 624}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:25:17,070] Trial 28 finished with values: [0.9284224250325945, 0.9424920127580716] and parameters: {'lr': 2.820859679289135e-05, 'batch_size': 8, 'num_epochs': 6, 'seed': 1368}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:26:04,066] Trial 29 finished with values: [0.9390162623300453, 0.9283387621945962] and parameters: {'lr': 2.671528926952868e-05, 'batch_size': 8, 'num_epochs': 5, 'seed': 8191}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:26:55,482] Trial 30 finished with values: [0.9385245901639344, 0.9180327868652459] and parameters: {'lr': 1.273369235391469e-05, 'batch_size': 16, 'num_epochs': 6, 'seed': 7993}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:27:42,434] Trial 31 finished with values: [0.9448961156278229, 0.9313725489994126] and parameters: {'lr': 2.5979818171495228e-05, 'batch_size': 8, 'num_epochs': 5, 'seed': 2494}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:28:16,424] Trial 32 finished with values: [0.9336803610845716, 0.9354838709467947] and parameters: {'lr': 1.1007872945885656e-05, 'batch_size': 32, 'num_epochs': 4, 'seed': 8251}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:28:59,638] Trial 33 finished with values: [0.9279149159663865, 0.932475884223245] and parameters: {'lr': 3.2110440031443184e-05, 'batch_size': 16, 'num_epochs': 5, 'seed': 3603}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:29:28,906] Trial 34 finished with values: [0.9256097560975609, 0.8910891088912908] and parameters: {'lr': 1.261543930826463e-05, 'batch_size': 8, 'num_epochs': 3, 'seed': 8098}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:29:55,838] Trial 35 finished with values: [0.9284224250325945, 0.9424920127580716] and parameters: {'lr': 1.568104956410148e-05, 'batch_size': 16, 'num_epochs': 3, 'seed': 984}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:30:22,786] Trial 36 finished with values: [0.9574771784232365, 0.9577922077716309] and parameters: {'lr': 1.2775202833491936e-05, 'batch_size': 16, 'num_epochs': 3, 'seed': 4534}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:30:52,046] Trial 37 finished with values: [0.9453278008298756, 0.9415584415378647] and parameters: {'lr': 2.6098314338286225e-05, 'batch_size': 8, 'num_epochs': 3, 'seed': 1270}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:31:35,225] Trial 38 finished with values: [0.9574771784232365, 0.9577922077716309] and parameters: {'lr': 4.6191477308204536e-05, 'batch_size': 16, 'num_epochs': 5, 'seed': 3554}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:32:13,318] Trial 39 finished with values: [0.9058157488419969, 0.9305993690630168] and parameters: {'lr': 1.2768533825418544e-05, 'batch_size': 8, 'num_epochs': 4, 'seed': 5464}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:33:00,232] Trial 40 finished with values: [0.9336803610845716, 0.9354838709467947] and parameters: {'lr': 3.2373269369526376e-05, 'batch_size': 8, 'num_epochs': 5, 'seed': 9024}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:33:27,222] Trial 41 finished with values: [0.9284224250325945, 0.9424920127580716] and parameters: {'lr': 3.1745405645098554e-05, 'batch_size': 16, 'num_epochs': 3, 'seed': 8616}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:33:52,976] Trial 42 finished with values: [0.9448961156278229, 0.9313725489994126] and parameters: {'lr': 3.5637948145469416e-05, 'batch_size': 32, 'num_epochs': 3, 'seed': 7233}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:34:22,180] Trial 43 finished with values: [0.8581342980545609, 0.7167832167675557] and parameters: {'lr': 2.3509556405853162e-05, 'batch_size': 8, 'num_epochs': 3, 'seed': 9867}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:35:05,446] Trial 44 finished with values: [0.9273809523809524, 0.9223300970666154] and parameters: {'lr': 1.7101391986148765e-05, 'batch_size': 16, 'num_epochs': 5, 'seed': 5447}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:35:43,548] Trial 45 finished with values: [0.939484126984127, 0.938511326840078] and parameters: {'lr': 4.343582602303995e-05, 'batch_size': 8, 'num_epochs': 4, 'seed': 3927}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:36:39,477] Trial 46 finished with values: [0.9390162623300453, 0.9283387621945962] and parameters: {'lr': 1.770451490968238e-05, 'batch_size': 8, 'num_epochs': 6, 'seed': 1677}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:37:20,820] Trial 47 finished with values: [0.9508196721311475, 0.9344262294881968] and parameters: {'lr': 4.150904887824992e-05, 'batch_size': 32, 'num_epochs': 5, 'seed': 3303}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:38:12,182] Trial 48 finished with values: [0.9512130098640362, 0.9446254071457363] and parameters: {'lr': 2.0910436723320073e-05, 'batch_size': 16, 'num_epochs': 6, 'seed': 1824}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-04-15 23:39:08,056] Trial 49 finished with values: [0.9512130098640362, 0.9446254071457363] and parameters: {'lr': 1.161188560465267e-05, 'batch_size': 8, 'num_epochs': 6, 'seed': 719}.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Top Trials (F1-macro & F2-class1):\n",
            "\n",
            "Trial 0\n",
            "F1-macro: 0.9575, F2 (class 1): 0.9578\n",
            "Precision (0): 0.9832, Recall (0): 0.9590\n",
            "Precision (1): 0.9219, Recall (1): 0.9672\n",
            "Seed: 1495\n",
            "Confusion Matrix:\n",
            "[[117   5]\n",
            " [  2  59]]\n",
            "\n",
            "Trial 1\n",
            "F1-macro: 0.9575, F2 (class 1): 0.9578\n",
            "Precision (0): 0.9832, Recall (0): 0.9590\n",
            "Precision (1): 0.9219, Recall (1): 0.9672\n",
            "Seed: 624\n",
            "Confusion Matrix:\n",
            "[[117   5]\n",
            " [  2  59]]\n",
            "\n",
            "Trial 2\n",
            "F1-macro: 0.9575, F2 (class 1): 0.9578\n",
            "Precision (0): 0.9832, Recall (0): 0.9590\n",
            "Precision (1): 0.9219, Recall (1): 0.9672\n",
            "Seed: 4534\n",
            "Confusion Matrix:\n",
            "[[117   5]\n",
            " [  2  59]]\n",
            "\n",
            "Trial 3\n",
            "F1-macro: 0.9575, F2 (class 1): 0.9578\n",
            "Precision (0): 0.9832, Recall (0): 0.9590\n",
            "Precision (1): 0.9219, Recall (1): 0.9672\n",
            "Seed: 3554\n",
            "Confusion Matrix:\n",
            "[[117   5]\n",
            " [  2  59]]\n",
            "\n",
            "🎯 Using best trial based on F1:\n",
            "  F1 = 0.9575, F2 = 0.9578\n",
            "  Params = {'lr': 2.526098960983148e-05, 'batch_size': 16, 'num_epochs': 4, 'seed': 1495}\n",
            "\n",
            "✅ Final model saved as 'bert_model_optimized_dual.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the target folder in Google Drive\n",
        "target_folder = '/content/drive/MyDrive/bert_predictions'\n",
        "os.makedirs(target_folder, exist_ok=True)  # create it if it doesn't exist\n",
        "\n",
        "# 3. Define the list of files you want to copy from Colab to Drive\n",
        "files_to_save = [\n",
        "    'bert_model_optimized_dual.pth',\n",
        "]\n",
        "\n",
        "# 4. Copy files to the Google Drive folder\n",
        "for file in files_to_save:\n",
        "    if os.path.exists(file):\n",
        "        shutil.copy(file, target_folder)\n",
        "        print(f\"✅ Copied: {file}\")\n",
        "    else:\n",
        "        print(f\"❌ File not found: {file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0RD2xhjfWCP",
        "outputId": "aff3a5f6-36e1-4aa8-d60a-befe80f4d10f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Copied: bert_model_optimized_dual.pth\n"
          ]
        }
      ]
    }
  ]
}